---
title: "Final Project"
author: "Elizabeth Chen & Benjamin Tompkins"
date: "5/6/2020"
output: html_document
---
## Introduction
Similar to common currencies, cryptocurrencies can be used to buy products and services. However, unlike other currencies, cryptocurrencies are digital and use cryptography to provide secure online transactions. Much of the interest in these unregulated currencies is to trade for profit even though cryptocurrencies can be in used regular purchase. Speculators at times drove prices of cryptocurrencies skyward. 

In this tutorial, we will cover the entire data science pipeline: data curation, parsing, and management; exploratory data analysis; hypothesis testing and machine learning. We will use R to carry out various techniques of predicting financial market movements, specifically volume of different cryptocurrencies trade. 

## Preface and Background
Cryptocurrency is a form of payment that can be exchanged online for products and services. Many companies have issued their own cryptocurrencies, often called tokens, which can be used specifically to purchase the products and services provided by the company. Cryptocurrency can be considered similar to arcade tokens or casino chips, which need to be purchased or exchanged with real currency.

Cryptocurrencies use a technology called blockchain, which is a decentralized technology spread across many computers that manages and records transactions. One of the appealing characteristics of cryptocurrencies is its security.

According to CoinMarketCap.com, a market research website, more than 2,200 different cryptocurrencies are traded publicly. The total value of all cryptocurrencies as of June 2019 was estimated to be $246 billion. Since the cryptocurrency market is still fairly young, the current stock prices of cryptocurrencies can vary quite a bit. We hope to do some analysis on the following types of cryptocurrencies to see if we can predict some current market trends: Bitcoin, Litecoin and Ethereum.

For more information on how cryptocurrencies work: https://blockgeeks.com/guides/what-is-cryptocurrency/
For more information on cryptocurrency prices: https://cointelegraph.com/explained/how-cryptocurrency-prices-work-explained

Created in 2009 by Satoshi Nakamoto, Bitcoin was the first widely adopted cryptocurrency. Bitcoin not only uses peer-to-peer technology to operate with no central authority or banks, but also collectively manages transactions and bitcoinâ€™s issuance. Bitcoin is open-source; its design is public, nobody owns or controls Bitcoin and everyone can take part. Nowadays, Bitcoin has become synonymous with cryptocurrency, however, this is not the only type of cryptocurrency available.
(https://medium.com/decryptionary/what-is-bitcoin-for-dummies-a-guide-for-beginners-8b3d9c0a8065)

Litecoin is one of the most prominent alternatives to Bitcoin and works upon the same fundamental principles. The transaction time of Litecoin is roughly two and a half minutes faster than that of Bitcoin. With four times as many Litecoins in circulation, it theoretically offers smaller divisions of coins to make smaller transaction values more feasible. Litecoin also uses a hashing algorithm, known as scrypt, which is supposed to keep Litecoin mining realistic for desktop users. Bitcoin uses the standard SHA256d algorithm which becomes more time as well as power intensive as time goes on. 
(https://www.forbes.com/sites/quora/2018/02/08/what-is-litecoin/#6b7bf4c333f7)
(https://www.wired.com/2013/08/litecoin/)

Ethereum is a cryptocurrency that took the technology behind bitcoin and expanded its capabilities. Ethereum is a decentralized network with its own interbet browser, coding language, and payment system. Etheruem ustilizes a peer-to-peer approach, where nodes download the Etheruem blockchain and enforce all the rules of the system, which allows the network to be honest and the nodes to recieve rewards. Ethereum seems to be a complex mode of cryptocurrency exchange. It will be interesting comparing it with other cryptocurrencies.
(https://cointelegraph.com/ethereum-for-beginners/what-is-ethereum)

## Environment Setup

Libraries used to conduct our tutorial through the data science pipeline. 
```{r setup}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(lubridate)
library(caret)
library(broom)
library(pracma)
library(caret)
library(rpart)
library(rpart.plot)
library(plotROC)
```

## Data Curation and Parsing

We are using datasets from https://www.kaggle.com/sudalairajkumar/cryptocurrencypricehistory#bitcoin_price.csv. This dataset has multiple .csv files for each type of cryptocurrency. In this specific tutorial we will be looking at three of these .csv files corresponding to three different cryptocurrencies. The cryptocurrencies we will be looking at are: Bitcoin, Ethereum, and Litecoin. We chose these three in particular because these were the ones that we had heard of and were fairly popular. CoinMarketCap, a website that tracks the value and performance of various cryptocurrencies, has all three of the chosen cryptocurrencies of this particular tutorial all within the top 10.
  
After downloading the dataset, we put each csv into its own table, then gave it an identifier of its type, then combined all three tables into one for easier data manipulation. All three datasets had the same column names making it easier to combine into something useful. We then used a lubridate function that made the Data column more useful for comparison and sorted by the date.

```{r load_data, warnings=FALSE}
bitcoin_tab <- read_csv("datasets/bitcoin_price.csv")
litecoin_tab <- read_csv("datasets/litecoin_price.csv")
ethereum_tab <- read_csv("datasets/ethereum_price.csv")
bitcoin_tab <- mutate(bitcoin_tab, coin_type="bitcoin")
litecoin_tab <- mutate(litecoin_tab, coin_type="litecoin")
ethereum_tab <- mutate(ethereum_tab, coin_type="ethereum")
crypto_tab <- bitcoin_tab %>%
  rbind(litecoin_tab) %>%
  rbind(ethereum_tab) %>%
  mutate(Date=mdy(Date)) %>% 
  arrange(desc(Date))

head(crypto_tab)
```

## Data Management

Currently in our dataset, we have the following attributes: 
* Date - Date refers to the calendar date for the particular row - 24 hours midnight to midnight
* Open - Open is what the price was at the beginning of the day
* High - Highest recorded trading price of the day
* Low - Lowest recorded trading price of the day
* Close - Close is what the price was at the end of the day
* Volume - Volume represents the monetary value of the currency traded in a 24 hour period, denoted in USD
* Market Cap - Market cap is circulating supply x price of the coin. For example, if you have 100 coins that are worth \$10 each your market cap is \$1,000

We want to add the following new attributes for our data analysis later on: spread and volume multipli.
* Close ratio is the daily close rate, min-maxed with the high and low values for the day. Close Ratio = (Close-Low)/(High-Low)
* Spread is the $USD difference between the high and low values for the day.
* Volume Multiplier is the constant relationship between spread and trading volume. Volume Multiplier = Volume/Spread
* Difference is the $USD difference between the opening and closing values for the day.

```{r add_attr}
crypto_tab = crypto_tab %>%
  mutate(close_ratio=(Close-Low)/(High-Low)) %>%
  mutate(spread=High-Low) %>%
  mutate(vol_mult = Volume/spread) %>%
  mutate(diff=Close-Open) %>%
  drop_na

head(crypto_tab)
```

## Exploratory Data Analysis

Now that we have our data all nice and sorted, let's begin some exploratory data analysis! We're going to want to analyze the trends and directions in the market values for our cryptocurrencies.

A great way to start analyzing our data is looking at the minimum and maximum values of volume and spread so we know where our bounds are. Mean, median and variance are also important measures of central tendency which can tell us about the averages, where the majority of the data lie, and the spread of our data.

``` {r analysis}
print("Bitcoin Analysis:")
bitcoin = crypto_tab %>%
  filter(coin_type=='bitcoin')
cat("Volume Min - ", min(bitcoin$Volume), "\n")
cat("Volume Max - ", max(bitcoin$Volume), "\n")
cat("Spread Min - ", min(bitcoin$spread), "\n")
cat("Spread Max - ", max(bitcoin$spread), "\n")
cat("Close Ratio Mean - ", mean(bitcoin$close_ratio), "\n")
cat("Close Ratio Median - ", median(bitcoin$close_ratio), "\n")
cat("Close Ratio Variance - ", var(bitcoin$close_ratio), "\n")

cat("\n")
print("Ethereum Analysis:")
ethereum = crypto_tab %>%
  filter(coin_type=='ethereum')
cat("Volume Min - ", min(ethereum$Volume), "\n")
cat("Volume Max - ", max(ethereum$Volume), "\n")
cat("Spread Min - ", min(ethereum$spread), "\n")
cat("Spread Max - ", max(ethereum$spread), "\n")
cat("Close Ratio Mean - ", mean(ethereum$close_ratio), "\n")
cat("Close Ratio Median - ", median(ethereum$close_ratio), "\n")
cat("Close Ratio Variance - ", var(ethereum$close_ratio), "\n")

cat("\n")
print("Litecoin Analysis:")
litecoin = crypto_tab %>%
  filter(coin_type=='litecoin')
cat("Volume Min - ", min(litecoin$Volume), "\n")
cat("Volume Max - ", max(litecoin$Volume), "\n")
cat("Spread Min - ", min(litecoin$spread), "\n")
cat("Spread Max - ", max(litecoin$spread), "\n")
cat("Close Ratio Mean - ", mean(litecoin$close_ratio), "\n")
cat("Close Ratio Median - ", median(litecoin$close_ratio), "\n")
cat("Close Ratio Variance - ", var(litecoin$close_ratio), "\n")
```

After gathering our data, we can clearly see there is a large range in volume and spread. The close ratio seems to have little variance, meaning the data points are close to the mean. However, this is still a little difficult to interpret so let's look at some visualizations.

``` {r open_plot}
crypto_tab %>%
  ggplot(aes(x=Date, y=Open, color=coin_type)) +
    geom_line()  +
    labs(title = "Opening Price over Time",
         x = "Date",
         y = "Open")
```

Here, we see that opening prices of cryptocurrencies increase over time, which makes sense due to rising popularity. Bitcoin appears to have a significantly higher opening prices compared to the other cryptocurencies (altcoin). We also notice that in late 2017 the opening price for Bitcoin significantly dropped with a slight revival in early 2018. The overall trend is a positive and increasing, linear for Ethereum and Litecoin.

``` {r close_plot}
crypto_tab %>%
  ggplot(aes(x=Date, y=Close, color=coin_type)) +
    geom_line()  +
    labs(title = "Closing Price over Time",
         x = "Date",
         y = "Closing")
```

Looking at the closing prices, we see roughly the same trends as in the opening prices.

Now, we are going to plot the difference between opening and closing prices to see the best and worst days for each cryptocurrency. 

``` {r diff}
crypto_tab %>%
  group_by(coin_type) %>%
  arrange(desc(diff)) %>%
  ggplot(aes(x=Date, y=diff, color=coin_type)) +
  geom_line() +
  labs(title = "Difference in Closing Price vs Opening Price over Time",
         x = "Date",
         y = "Difference")
```

Based on the chart, The end of 2017 had a huge boom with the best daily differences occuring in December 2017. In early 2018, however, all three cryptocurrencies experience their worst daily loss, signifying the event called the 2018 cryptocurrency crash, which occured from January 6, 2016 to February 6, 2018. In this period Bitcoin fell by about 65%, after an unprecedented boom in 2017. (en.wikipedia.org/wiki/2018_cryptocurrency_crash)

Next, let's look at spread which is the difference between the high and low for that date. This will tells us more about the volatility of each cryptocurrency.

```{r spread}
crypto_tab %>%
  group_by(coin_type) %>%
  arrange(desc(spread)) %>%
  ggplot(aes(x=Date, y=spread, color=coin_type)) +
  geom_line() +
  labs(title = "Spread over Time",
         x = "Date",
         y = "Spread")
```

Now, we are going to look at close ratio over time.
``` {r ratio}
crypto_tab %>%
  ggplot(aes(x=Date, y=close_ratio, color=coin_type)) +
  geom_point() +
  geom_smooth(method='lm') +
  labs(title = "Close Ratio over Time",
         x = "Date",
         y = "Close Ratio")
```

Looking at this plot, the close ratio seems to have a slight positive increasing linear trend over time, but this doesn't really tell us much.

Let's try looking at volume next!

```{r vol_plot}
crypto_tab %>%
  ggplot(aes(x=Date, y=Volume, color=coin_type)) +
  geom_line() +
  labs(title = "Volume over Time",
         x = "Date",
         y = "Volume")
```

The distribution of volume over time is skewed left which makes sense since trading of cryptocurrencies increases over time. This also tells us that from 2014 to early 2016 there was little trading compared to post 2017. 

## Hypothesis Testing
From now on, we will want to filter our data to be post-2017 since the cryptocurrency exchange was bankrupt during 2014 and was still being reestablished through late 2016.

```{r date}
crypto_tab = crypto_tab %>%
  filter(Date >= "2017-01-01") 
  
head(crypto_tab)
```

Let's take another look at volume and spread.

```{r vol_plot2, warning=FALSE, message=FALSE}
crypto_tab %>%
  ggplot(aes(x=Date, y=Volume, color=coin_type)) +
  geom_line() +
  geom_smooth() +
  labs(title = "Volume over Time",
         x = "Date",
         y = "Volume")
```

```{r spread2, warning=FALSE, message=FALSE}
crypto_tab %>%
  group_by(coin_type) %>%
  arrange(desc(spread)) %>%
  ggplot(aes(x=Date, y=spread, color=coin_type)) +
  geom_line() +
  geom_smooth() +
  labs(title = "Spread over Time",
         x = "Date",
         y = "Spread")
```

Looking at these two attributes, volume and spread, we can see they both have a positive, somewhat linear increasing trend. Let's see if spread and volume have a linear relationship as well.

```{r lm, warning=FALSE, message=FALSE}
crypto_tab %>%
  group_by(coin_type) %>%
  ggplot(aes(x=spread, y=Volume, color=coin_type)) +
  geom_line() +
  geom_smooth(method='lm') +
  labs(title = "Spread vs. Volume",
         x = "Spread",
         y = "Volume")
```

This leads us to the null hypothesis: there is no relationship between spread and volume. Our hypothesis being there is a linear relationship between spread and volume.

```{r rm}
reg_model <- lm(Volume~spread, data=crypto_tab)
reg_model_stats <- reg_model %>%
  tidy()

reg_model_stats
```

We reject the null hypothesis since the p-value (0.00) is less than our alpha of (.05). The p-value is the probability that we observe our sample results given the null hypothesis is true, meaning there is no relationship between year and life expectancy. 

Now, we are going to take a look at the volume multiplier.
```{r lm2, warning=FALSE, message=FALSE}
crypto_tab %>%
  group_by(coin_type) %>%
  ggplot(aes(x=spread, y=vol_mult, color=coin_type)) +
  geom_point() +
  geom_smooth(method='lm') +
  labs(title = "Spread vs. Volume Multiplier",
         x = "Spread",
         y = "Volume Multiplier")
```

Looking at this graph, we confirm our hypothesis that we can predict the volume based on the spread. Since the volume multiplier is constant, we can use that number to predict volume based on spread, but this only seems to works for Bitcoin.

## Machine Learning: Decision Tree

We start our exploration into machine learning with Decsision Trees. Decision Trees are quite simple. You traverse the tree by starting at the top and making a decision based on a boolean statement. If your parameters return true at a fork, traverse left down the tree, else go down the right tree. You continue this pattern of decsions until you reach a leaf, and within this leaf should be the predicted value. 
We will now show the decision tree in action. In this example, we want to see if we can predict the High value of the cryptocurrency based on its coin type and date. First, we will make and show a decision tree to give an overall idea of the general structure, then we will see if we can make a decision tree model that can accurately make predictions.

First, lets make a tree. We start by calling rpart, which "grows" a tree given the data parameters we wish to use, the data with which we want the tree to be built upon, and a control function. Here, I use a built in control function that stops computation once a cp value is reached, but this control function can be replaced with one that you write or another built in one. The purpose of limiting the complexity is to make a model that is complex enough to be acurate, but not too complex to only work with this dataset.



```{r creating tree}

tree <- rpart(High~coin_type+Date, data = crypto_tab, control = rpart.control(cp = 0.0001))

printcp(tree)

```
The chart produced is showing the error and standard deviation as the number of splits is increased until we reach the cp value in designated in out control function. 

We then next find the tree with the best cp, which is the cp value that is the smallest and should be the same value as the cp value given in our control function. We next prune the tree, to simplify it and remove uneccessary forks and complexity. We then print our tree using prp, which will print out the tree in a pretty format.
``` {r prune}
bestcp <- tree$cptable[which.min(tree$cptable[,"xerror"]),"CP"]

tree.pruned <- prune(tree, cp = bestcp)

prp(tree.pruned, faclen = 0, cex = 0.6, extra = 1)
```

As you can see from this tree, the first fork splits into two trees based on if the coin type was litecoin or ethereum, or not. This can be seen in the chart for High over Date, grouped by coin type. Litecoin and ethereum are relatively close to each other compared to bitcoin, so it makes sense for that to be the initial split that the tree makes. You can see further down on the tree on the left that eventually it does split ethereum and litecoin, but not for a little but, signifying their similarities in high values.

Now, we will apply the production of decision trees into a model for predicting. To accomplish this we split our data into a partition of data that we will train the model on and data we train the model on. I also remove unneccessary attributes that are not needed in our prediction of the High value based on Date and Coin Type. After that, we create the model based on our training set using the same function we used in the above example. We then run our test data through the model to predict the High for each entity. I then calculate the squared error for each value, which is $$(predicted - actual)^2$$, sum up all these squared errors and take the squared root. I judge the accuracy of my model based on this root mean squared error value (RMSE). We want to have a rmse relative to the range of values.

``` {r partition}
set.seed(123)
prediction_set <- crypto_tab %>%
  select(-Open, -Low, -Close, -Volume, -`Market Cap`, -close_ratio, -diff)
index <- createDataPartition(y=prediction_set$spread, p=0.8, list=FALSE)

data_train <- prediction_set[index,]
data_test <- prediction_set[-index,]

decision_tree <- rpart(High~coin_type+Date, data=data_train)
predictions_decision <- predict(decision_tree, data_test)
cbind(data_test, predictions_decision) %>%
  mutate(se = ((High - predictions_decision)^2)/n()) %>%
  summarize(rmse = sqrt(sum(se)))

range(crypto_tab$High)
```

My model has a RMSE of 753.0129. This isnt a terrible value, but certainly isnt great. This means that on average, our prediction of high is off by 753.0129. With a range of 3.77 to 20089.00 means that this value is relatively ok, but if I was an investorin cryptocurrencies, I wouldn't want my prediction to have an error of 753, so lets see if we can get it to be smaller.

Another, method for creating and determining the strength of a model is Cross Validation. In this example, we will be using 10 fold cross validation. This means that we split our data into 10 partitions, use 9 partions to train the data, and one partiotion to test, and we repeat this 10 times until all partions are used to test. We do this to... TODO.

To train a fit for the model, we use the train function included in the caret package. This function first takes in a formula for prediction, which in our case is predicting High based on coin type and date. Then it takes the data we are using as a parameter along with the method used for the model, and in our case we use a  decision tree, so we set our method to be equal to "rpart". Next the train function takes in a control function. This is were the 10-fold cross validation comes it. We use the trainControl function, and give it parameters, cv and 10 for 10 fold cross validation. We also give the train function a tuneLength... TODO i have no clue why



``` {r train}
train_control <- trainControl(method="cv", number=10)
tree_fit <- train(High~coin_type+Date, data=crypto_tab, method="rpart", trControl=train_control, tuneLength=10)
tree_fit
```

As you can see, most of our models produce RMSE lower than our model above, which just used a simple partioning of the data. A 404.1065 is better than our previously computed 753.01, but is still not entirely great. This shows that the Decsion Tree model is not the most accurate model in predicting. It also shows the complexity of predicting the price of bitcoin over time. There are more outside factors that affect the price that are not present in this dataset and probably couldnt be measured to even be put in a dataset. TODO go in more depth about the complexity of computing price. 


